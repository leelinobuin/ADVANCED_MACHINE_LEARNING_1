{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","metadata":{"id":"X5cGnvi7A3Un","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713249249324,"user_tz":-540,"elapsed":9,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"f252de9d-777b-47e5-8b09-1ba7f2eae87b"},"source":[" !nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Apr 16 06:34:08 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   60C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"0Y2OsX2EQU3v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713252137856,"user_tz":-540,"elapsed":25102,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"78e3544b-08af-4789-b271-26ce2aee9ac2"},"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","\n","# This mounts your google drive storage to this code\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"AryDcrN7QU31","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713252140859,"user_tz":-540,"elapsed":302,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"8c7f38af-3b62-4af8-f02a-94b82f54a9fd"},"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")\n","\n","root = '/content/gdrive/My Drive/Test/'\n","\n","# root = './'\n","# if not os.path.exists(root):\n","#     os.makedirs(root)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"code","metadata":{"id":"6HVAXJ7DQU35","executionInfo":{"status":"ok","timestamp":1713252371217,"user_tz":-540,"elapsed":284,"user":{"displayName":"홍세연","userId":"01071231686833557746"}}},"source":["# settings for data normalization\n","# trans = transforms.Compose([transform.ToTensor(), transform.Normalize((0.5,),(1.0,))])\n","trans = transforms.ToTensor()\n","# trans = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip()])\n","\n","\n","train_data = datasets.FashionMNIST(\n","    root=root,\n","    train=True,\n","    download=True,\n","    transform=trans,\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=root,\n","    train=False,\n","    download=True,\n","    transform=trans,\n",")\n","\n","\n","batch_size = 50\n","train_loader = torch.utils.data.DataLoader(train_data,batch_size=batch_size,shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_data,batch_size=batch_size,shuffle=False)\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Linear Classification\n","class LinearClassification(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear = nn.Sequential(\n","            nn.Linear(28*28, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear(x)\n","        return logits\n","\n","model = LinearClassification().to(device)\n","print(model)\n"],"metadata":{"id":"wdDmKu9z_eu3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713252156326,"user_tz":-540,"elapsed":814,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"bc1e6719-fca8-4f8c-fa7d-b4894ce7a159"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["LinearClassification(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear): Sequential(\n","    (0): Linear(in_features=784, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","source":[" # Multi-layer Perceptron\n"," class NeuralNetwork(nn.Module):\n","     def __init__(self):\n","         super().__init__()\n","         self.flatten = nn.Flatten()\n","         self.linear_relu_stack = nn.Sequential(\n","             nn.Linear(28*28, 512),\n","             nn.ReLU(),\n","             nn.Linear(512, 512),\n","             nn.ReLU(),\n","             nn.Linear(512, 10)\n","         )\n","\n","     def forward(self, x):\n","         x = self.flatten(x)\n","         logits = self.linear_relu_stack(x)\n","         return logits\n","\n"," model = NeuralNetwork().to(device)\n"," print(model)\n"],"metadata":{"id":"bhPn_4CvsfV9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713252160418,"user_tz":-540,"elapsed":335,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"7d8887fa-5493-4118-e330-79323212f924"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"n4kyTJnAQU39","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713252202596,"user_tz":-540,"elapsed":345,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"debed01e-4d01-47d2-dcb1-f6cd04927597"},"source":["# define the CNN:\n","# two convolution layers followed by two linear layers\n","\n","class MyConvNet(nn.Module):   # nn.Module should be inherited for the neural network configuration so that it can work with backpropagation APIs\n","    def __init__(self):    # define layers: two conv layers and two linear (fully connected) layers\n","        super(MyConvNet, self).__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv2d(1, 32, 5),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            nn.Conv2d(32, 64, 5),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            nn.Flatten(),\n","            nn.Linear(4*4*64, 512),\n","            nn.Linear(512, 10)\n","        )\n","\n","    # network connection: two conv layers, each followed by relu and max-pooling with (2x2) kernel, and two linear layer\n","    def forward(self, x):\n","        logits = self.conv_layers(x)\n","        return(logits)\n","\n","\n","# generate neural net model\n","model = MyConvNet().to(device)\n","print(model)\n"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["MyConvNet(\n","  (conv_layers): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Flatten(start_dim=1, end_dim=-1)\n","    (7): Linear(in_features=1024, out_features=512, bias=True)\n","    (8): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"code","metadata":{"id":"TZU3HDu0QU4B","executionInfo":{"status":"ok","timestamp":1713252224681,"user_tz":-540,"elapsed":276,"user":{"displayName":"홍세연","userId":"01071231686833557746"}}},"source":["optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n","\n","criterion = nn.CrossEntropyLoss()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"b0uJzp41QU4G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713252342866,"user_tz":-540,"elapsed":115537,"user":{"displayName":"홍세연","userId":"01071231686833557746"}},"outputId":"dabdc312-7b8c-4d78-88ec-373edc5a041f"},"source":["# training and test\n","\n","# epoch: 10\n","# data dimension: batch_size x Channels x Height x Width (NCHW)\n","for epoch in range(10):\n","    # training phase\n","    # model.train()\n","    current_loss= 0.0\n","    for batch_num, (x, target) in enumerate(train_loader):\n","        x, target = x.to(device), target.to(device)\n","\n","        out = model(x)\n","        loss = criterion(out,target)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        current_loss += loss\n","\n","        # display the training loss in every 100 batches\n","        if (batch_num+1)%100 == 0 or (batch_num+1)%100 == len(train_loader):\n","            print('epoch: %d, batch_num: %d, current_loss: %.3f' %(epoch, batch_num+1, current_loss/100))\n","            current_loss = 0.0\n","\n","\n","    # test phase\n","    with torch.no_grad():\n","        # model.eval()\n","        total_samples = 0.0\n","        correct_samples = 0.0\n","        for (x, target) in test_loader:\n","            x, target = x.to(device), target.to(device)\n","            out = model(x)\n","            pred = torch.argmax(out,1)\n","            correct_samples += (pred == target).sum()\n","        print('Accuracy: %.3f' %(100*float(correct_samples) / float(len(test_data))))\n","\n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 0, batch_num: 100, current_loss: 0.926\n","epoch: 0, batch_num: 200, current_loss: 0.594\n","epoch: 0, batch_num: 300, current_loss: 0.495\n","epoch: 0, batch_num: 400, current_loss: 0.481\n","epoch: 0, batch_num: 500, current_loss: 0.451\n","epoch: 0, batch_num: 600, current_loss: 0.412\n","epoch: 0, batch_num: 700, current_loss: 0.386\n","epoch: 0, batch_num: 800, current_loss: 0.373\n","epoch: 0, batch_num: 900, current_loss: 0.371\n","epoch: 0, batch_num: 1000, current_loss: 0.364\n","epoch: 0, batch_num: 1100, current_loss: 0.371\n","epoch: 0, batch_num: 1200, current_loss: 0.357\n","Accuracy: 86.000\n","epoch: 1, batch_num: 100, current_loss: 0.320\n","epoch: 1, batch_num: 200, current_loss: 0.350\n","epoch: 1, batch_num: 300, current_loss: 0.322\n","epoch: 1, batch_num: 400, current_loss: 0.314\n","epoch: 1, batch_num: 500, current_loss: 0.335\n","epoch: 1, batch_num: 600, current_loss: 0.307\n","epoch: 1, batch_num: 700, current_loss: 0.331\n","epoch: 1, batch_num: 800, current_loss: 0.306\n","epoch: 1, batch_num: 900, current_loss: 0.316\n","epoch: 1, batch_num: 1000, current_loss: 0.305\n","epoch: 1, batch_num: 1100, current_loss: 0.317\n","epoch: 1, batch_num: 1200, current_loss: 0.302\n","Accuracy: 88.190\n","epoch: 2, batch_num: 100, current_loss: 0.295\n","epoch: 2, batch_num: 200, current_loss: 0.254\n","epoch: 2, batch_num: 300, current_loss: 0.277\n","epoch: 2, batch_num: 400, current_loss: 0.282\n","epoch: 2, batch_num: 500, current_loss: 0.280\n","epoch: 2, batch_num: 600, current_loss: 0.273\n","epoch: 2, batch_num: 700, current_loss: 0.296\n","epoch: 2, batch_num: 800, current_loss: 0.283\n","epoch: 2, batch_num: 900, current_loss: 0.270\n","epoch: 2, batch_num: 1000, current_loss: 0.275\n","epoch: 2, batch_num: 1100, current_loss: 0.256\n","epoch: 2, batch_num: 1200, current_loss: 0.267\n","Accuracy: 89.030\n","epoch: 3, batch_num: 100, current_loss: 0.257\n","epoch: 3, batch_num: 200, current_loss: 0.245\n","epoch: 3, batch_num: 300, current_loss: 0.244\n","epoch: 3, batch_num: 400, current_loss: 0.249\n","epoch: 3, batch_num: 500, current_loss: 0.261\n","epoch: 3, batch_num: 600, current_loss: 0.249\n","epoch: 3, batch_num: 700, current_loss: 0.258\n","epoch: 3, batch_num: 800, current_loss: 0.267\n","epoch: 3, batch_num: 900, current_loss: 0.260\n","epoch: 3, batch_num: 1000, current_loss: 0.252\n","epoch: 3, batch_num: 1100, current_loss: 0.250\n","epoch: 3, batch_num: 1200, current_loss: 0.240\n","Accuracy: 89.770\n","epoch: 4, batch_num: 100, current_loss: 0.219\n","epoch: 4, batch_num: 200, current_loss: 0.221\n","epoch: 4, batch_num: 300, current_loss: 0.230\n","epoch: 4, batch_num: 400, current_loss: 0.230\n","epoch: 4, batch_num: 500, current_loss: 0.237\n","epoch: 4, batch_num: 600, current_loss: 0.231\n","epoch: 4, batch_num: 700, current_loss: 0.233\n","epoch: 4, batch_num: 800, current_loss: 0.224\n","epoch: 4, batch_num: 900, current_loss: 0.257\n","epoch: 4, batch_num: 1000, current_loss: 0.246\n","epoch: 4, batch_num: 1100, current_loss: 0.227\n","epoch: 4, batch_num: 1200, current_loss: 0.233\n","Accuracy: 89.620\n","epoch: 5, batch_num: 100, current_loss: 0.208\n","epoch: 5, batch_num: 200, current_loss: 0.207\n","epoch: 5, batch_num: 300, current_loss: 0.194\n","epoch: 5, batch_num: 400, current_loss: 0.205\n","epoch: 5, batch_num: 500, current_loss: 0.210\n","epoch: 5, batch_num: 600, current_loss: 0.224\n","epoch: 5, batch_num: 700, current_loss: 0.224\n","epoch: 5, batch_num: 800, current_loss: 0.228\n","epoch: 5, batch_num: 900, current_loss: 0.221\n","epoch: 5, batch_num: 1000, current_loss: 0.219\n","epoch: 5, batch_num: 1100, current_loss: 0.223\n","epoch: 5, batch_num: 1200, current_loss: 0.214\n","Accuracy: 89.150\n","epoch: 6, batch_num: 100, current_loss: 0.188\n","epoch: 6, batch_num: 200, current_loss: 0.188\n","epoch: 6, batch_num: 300, current_loss: 0.205\n","epoch: 6, batch_num: 400, current_loss: 0.192\n","epoch: 6, batch_num: 500, current_loss: 0.205\n","epoch: 6, batch_num: 600, current_loss: 0.222\n","epoch: 6, batch_num: 700, current_loss: 0.189\n","epoch: 6, batch_num: 800, current_loss: 0.195\n","epoch: 6, batch_num: 900, current_loss: 0.203\n","epoch: 6, batch_num: 1000, current_loss: 0.207\n","epoch: 6, batch_num: 1100, current_loss: 0.198\n","epoch: 6, batch_num: 1200, current_loss: 0.215\n","Accuracy: 89.810\n","epoch: 7, batch_num: 100, current_loss: 0.162\n","epoch: 7, batch_num: 200, current_loss: 0.189\n","epoch: 7, batch_num: 300, current_loss: 0.173\n","epoch: 7, batch_num: 400, current_loss: 0.181\n","epoch: 7, batch_num: 500, current_loss: 0.198\n","epoch: 7, batch_num: 600, current_loss: 0.186\n","epoch: 7, batch_num: 700, current_loss: 0.196\n","epoch: 7, batch_num: 800, current_loss: 0.188\n","epoch: 7, batch_num: 900, current_loss: 0.193\n","epoch: 7, batch_num: 1000, current_loss: 0.195\n","epoch: 7, batch_num: 1100, current_loss: 0.190\n","epoch: 7, batch_num: 1200, current_loss: 0.202\n","Accuracy: 89.120\n","epoch: 8, batch_num: 100, current_loss: 0.166\n","epoch: 8, batch_num: 200, current_loss: 0.172\n","epoch: 8, batch_num: 300, current_loss: 0.173\n","epoch: 8, batch_num: 400, current_loss: 0.163\n","epoch: 8, batch_num: 500, current_loss: 0.179\n","epoch: 8, batch_num: 600, current_loss: 0.185\n","epoch: 8, batch_num: 700, current_loss: 0.186\n","epoch: 8, batch_num: 800, current_loss: 0.175\n","epoch: 8, batch_num: 900, current_loss: 0.181\n","epoch: 8, batch_num: 1000, current_loss: 0.175\n","epoch: 8, batch_num: 1100, current_loss: 0.166\n","epoch: 8, batch_num: 1200, current_loss: 0.190\n","Accuracy: 90.450\n","epoch: 9, batch_num: 100, current_loss: 0.146\n","epoch: 9, batch_num: 200, current_loss: 0.161\n","epoch: 9, batch_num: 300, current_loss: 0.162\n","epoch: 9, batch_num: 400, current_loss: 0.175\n","epoch: 9, batch_num: 500, current_loss: 0.154\n","epoch: 9, batch_num: 600, current_loss: 0.170\n","epoch: 9, batch_num: 700, current_loss: 0.151\n","epoch: 9, batch_num: 800, current_loss: 0.187\n","epoch: 9, batch_num: 900, current_loss: 0.163\n","epoch: 9, batch_num: 1000, current_loss: 0.166\n","epoch: 9, batch_num: 1100, current_loss: 0.177\n","epoch: 9, batch_num: 1200, current_loss: 0.170\n","Accuracy: 89.930\n"]}]},{"cell_type":"code","metadata":{"id":"kdAbm_TvQU4N"},"source":["# Display Some test results\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","classes = [\n","    \"T-shirt/top\",\n","    \"Trouser\",\n","    \"Pullover\",\n","    \"Dress\",\n","    \"Coat\",\n","    \"Sandal\",\n","    \"Shirt\",\n","    \"Sneaker\",\n","    \"Bag\",\n","    \"Ankle boot\",\n","]\n","\n","# take one batch of the data\n","test_data, test_labels = next(iter(test_loader))\n","\n","# if cuda_available:\n","test_data, test_labels = test_data.to(device), test_labels.to(device)\n","out = model(test_data)              # put the test data to the trained network\n","pred = torch.argmax(out,1)          # prediction to the highest probability\n","\n","\n","sample_index = np.random.choice(batch_size, size=12)     # take 12 random sample index\n","num_samples = sample_index.size\n","\n","random_samples = test_data[sample_index].cpu().numpy()\n","\n","plt.figure(figsize=(12, 12))\n","\n","# display test samples\n","for k in range(num_samples):\n","    plt.subplot(4, 4, k + 1)\n","    plt.imshow(random_samples[k].reshape(28, 28),cmap='Greys')\n","    plt.title(\"True: \" + str( classes[test_labels[sample_index[k]].item()]) + \",\\nPred: \" + str(classes[pred[sample_index[k]].item()]))\n","    plt.axis('off')\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# save model\n","torch.save(model, root + 'my_CNN_model.pth')\n","\n","# load model\n","# model = torch.load('my_CNN_model.pth')"],"metadata":{"id":"qhPBxl3OO09E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # save model weights\n","# torch.save(model.state_dict(), 'model_weights.pth')\n","\n","# # load model weights\n","# model = MyConvNet()\n","# model.load_state_dict(torch.load('model_weights.pth'))\n"],"metadata":{"id":"uLBE-ZKbP0oJ"},"execution_count":null,"outputs":[]}]}